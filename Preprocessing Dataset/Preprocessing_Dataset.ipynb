{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mbti_1(C).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posts'] = df['posts'].apply(lambda x: re.sub(r'http\\S+', 'URL', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return text.replace('URL', '')\n",
    "\n",
    "df['posts'] = df['posts'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  ' and intj moments    sportscenter not top ten...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____    course, to which I say I k...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n",
      "5  INTJ  '18/37 @.@|||Science  is not perfect. No scien...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posts'] = df['posts'].replace(r'\\|\\|\\|', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(r'[^a-zA-Z\\s]', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ   and intj moments    sportscenter not top ten ...\n",
      "1  ENTP  Im finding the lack of me in these posts very ...\n",
      "2  INTP  Good one      course to which I say I know tha...\n",
      "3  INTJ  Dear INTP   I enjoyed our conversation the oth...\n",
      "4  ENTJ  Youre fired Thats another silly misconception ...\n",
      "5  INTJ    Science  is not perfect No scientist claims ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_regex = re.compile(r'\\b(?:ENFJ|ENFP|ENTJ|ENTP|ESFJ|ESFP|ESTJ|ESTP|INFJ|INFP|INTJ|INTP|ISFJ|ISFP|ISTJ|ISTP|enfj|enfp|entj|entp|esfj|esfp|estj|estp|infj|infp|intj|intp|isfj|isfp|istj|istp)\\b')\n",
    "\n",
    "df['posts'] = df['posts'].apply(lambda x: re.sub(mbti_regex, '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split() if word.lower() not in stop_words)\n",
    "    return text\n",
    "\n",
    "df['posts'] = df['posts'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  moments sportscenter top ten plays pranks life...\n",
      "1  ENTP  Im finding lack posts alarming Sex boring posi...\n",
      "2  INTP  Good one course say know thats blessing curse ...\n",
      "3  INTJ  Dear enjoyed conversation day Esoteric gabbing...\n",
      "4  ENTJ  Youre fired Thats another silly misconception ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posts'] = df['posts'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  moments sportscenter top ten plays pranks life...\n",
      "1  ENTP  im finding lack posts alarming sex boring posi...\n",
      "2  INTP  good one course say know thats blessing curse ...\n",
      "3  INTJ  dear enjoyed conversation day esoteric gabbing...\n",
      "4  ENTJ  youre fired thats another silly misconception ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  \n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged_words]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "df['posts'] = df['posts'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  moment sportscenter top ten play prank lifecha...\n",
      "1  ENTP  im find lack post alarm sex boring position of...\n",
      "2  INTP  good one course say know thats bless curse abs...\n",
      "3  INTJ  dear enjoyed conversation day esoteric gabbing...\n",
      "4  ENTJ  youre fire thats another silly misconception a...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Clear_mbti.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
